# LLM Providers (set the one you use)
OPENAI_API_KEY=
GOOGLE_API_KEY=
ANTHROPIC_API_KEY=
XAI_API_KEY=
OPENROUTER_API_KEY=

# API Server Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Celery + Redis Configuration
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0
REDIS_MAX_CONNECTIONS=20

# Docker Compose Service Networking (override for Docker)
# Use these when running in Docker, localhost when running locally
REDIS_HOST=redis
REDIS_PORT=6379
OLLAMA_BASE_URL=http://ollama:11434

# TradingAgents Configuration
# Backend URL for LLM API (OpenAI-compatible endpoint)
BACKEND_URL=https://api.openai.com/v1

# Per-Job Config Options (via API POST /jobs):
# These can be overridden per-job via the config field:
# - llm_provider: openai|anthropic|google|xai|ollama|openrouter
# - deep_think_llm: model name for complex reasoning
# - quick_think_llm: model name for quick tasks
# - max_debate_rounds: 1-5 (default: 1)
# - max_risk_discuss_rounds: 1-3 (default: 1)
# - selected_analysts: ["market", "social", "news", "fundamentals"]
# - backend_url: custom API endpoint URL
# - data_vendors: dict of vendor configurations

# Worker Configuration
CELERY_WORKER_CONCURRENCY=2
CELERY_WORKER_MAX_TASKS_PER_CHILD=50

# Results Storage (bind-mounted from host)
RESULTS_DIR=/data/results
CACHE_DIR=/app/tradingagents/dataflows/data_cache

# Storage Management:
# Results are stored in host directory: ./results/{ticker}/{YYYYMMDD}/
# - state.json - Full analysis state dict
# - decision.txt - Trading decision (BUY/SELL/HOLD)
# - market_report.txt - Market analyst report
# - sentiment_report.txt - Sentiment analyst report
# - news_report.txt - News analyst report
# - fundamentals_report.txt - Fundamentals analyst report
#
# Cache stored in: ./tradingagents/dataflows/data_cache/
#
# Cleanup: Simply delete files from ./results/ or ./tradingagents/dataflows/data_cache/
# NOTE: When scaling to multiple containers, migrate to cloud storage (S3, etc.)
