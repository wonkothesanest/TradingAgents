# LLM Providers (set the one you use)
OPENAI_API_KEY=
GOOGLE_API_KEY=
ANTHROPIC_API_KEY=
XAI_API_KEY=
OPENROUTER_API_KEY=

# API Server Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Celery + Redis Configuration
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0
REDIS_MAX_CONNECTIONS=20

# Docker Compose Service Networking (override for Docker)
# Use these when running in Docker, localhost when running locally
REDIS_HOST=redis
REDIS_PORT=6379
OLLAMA_BASE_URL=http://ollama:11434

# TradingAgents Configuration
# Backend URL for LLM API (OpenAI-compatible endpoint)
BACKEND_URL=https://api.openai.com/v1

# Per-Job Config Options (via API POST /jobs):
# These can be overridden per-job via the config field:
# - llm_provider: openai|anthropic|google|xai|ollama|openrouter
# - deep_think_llm: model name for complex reasoning
# - quick_think_llm: model name for quick tasks
# - max_debate_rounds: 1-5 (default: 1)
# - max_risk_discuss_rounds: 1-3 (default: 1)
# - selected_analysts: ["market", "social", "news", "fundamentals"]
# - backend_url: custom API endpoint URL
# - data_vendors: dict of vendor configurations

# Worker Configuration
CELERY_WORKER_CONCURRENCY=2
CELERY_WORKER_MAX_TASKS_PER_CHILD=50
